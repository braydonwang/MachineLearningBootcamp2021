{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week3Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEslPzD4HNPG"
      },
      "source": [
        "ML Bootcamp 2021 - Week 3: Assignment\n",
        "\n",
        "- In this week you will learn more about the Pandas and specifically use it to create features\n",
        "- Finally these features will be used to train a Logistic Regression model and you will submit your solution to the Kaggle ****Titanic Machine Learning from Disaster**** competition\n",
        "- The comments will have most of the instructions\n",
        "- Attempt the questions using only python/pandas as much as possible as it is a very in-demand skill right now and learning it will be beneficial\n",
        "\n",
        "## USE TRAIN DATASET FROM THE TITANIC DATASET PROVIDED ONLY UNLESS SPECIFIED"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyU4EAcwHTAt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "226d81b8-e07c-46c4-f580-0924c7d5147b"
      },
      "source": [
        "# Import the necessary Libraries here\n",
        "import pandas as pd\n",
        "import re\n",
        "import sklearn\n",
        "!pip install category_encoders\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 13.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 14.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 3.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.19.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.0.1)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAuyyEi1HmR_"
      },
      "source": [
        "## Q1. What is the average ticket price per ticket class(Pclass) for each individual port of embarkation? In other words, what is the price of each ticket class for each category of \"Embarked\" column?\n",
        "\n",
        "## Your answer should be in the following format as a Python Dictionary\n",
        "\n",
        "{<br>\n",
        "  (Pclass,Embarked Category) : Avg Fare<br>\n",
        "}\n",
        "\n",
        "Eg:\n",
        "\n",
        "{<br>\n",
        " (1, 'C'): Avg Fare,<br>\n",
        " (1, 'Q'): Avg Fare,<br>\n",
        " (1, 'S'): Avg Fare,<br>\n",
        " .<br>\n",
        " .<br>\n",
        " .<br>\n",
        " so on..<br>\n",
        "}\n",
        "\n",
        "\n",
        "## You can verify your answer as follows: \n",
        " - For the \"Embarked\" category 'Q' and 'Pclass' of 1 the average ticket price is \\$ 90\n",
        " - For the \"Embarked\" category 'S' and 'Pclass' of 3 the average ticket price is \\$ 14.64"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtklSy8ayxlH",
        "outputId": "ca71322a-4356-4714-881d-3433bc0b8e45"
      },
      "source": [
        "###### CODE ######\n",
        "df = pd.read_csv(\"./train.csv\")\n",
        "df[df['Embarked'] == 'C'].groupby('Pclass')['Fare'].mean().round(2)\n",
        "df[df['Embarked'] == 'Q'].groupby('Pclass')['Fare'].mean().round(2)\n",
        "df[df['Embarked'] == 'S'].groupby('Pclass')['Fare'].mean().round(2)\n",
        "###### CODE ######\n",
        "\n",
        "##### ANSWER #####\n",
        "{\n",
        " (1,'C'): 104.72,\n",
        " (2,'C'): 25.36,\n",
        " (3,'C'): 11.21,\n",
        " (1,'Q'): 90.00,\n",
        " (2,'Q'): 12.35,\n",
        " (3,'Q'): 11.18,\n",
        " (1,'S'): 70.36,\n",
        " (2,'S'): 20.33,\n",
        " (3,'S'): 14.64\n",
        "}\n",
        "##### ANSWER #####"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{(1, 'C'): 104.72,\n",
              " (1, 'Q'): 90.0,\n",
              " (1, 'S'): 70.36,\n",
              " (2, 'C'): 25.36,\n",
              " (2, 'Q'): 12.35,\n",
              " (2, 'S'): 20.33,\n",
              " (3, 'C'): 11.21,\n",
              " (3, 'Q'): 11.18,\n",
              " (3, 'S'): 14.64}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oph5WCmrKKFj"
      },
      "source": [
        "## Q2. Create the \"Title\" feature in your dataset as an additional column and call it \"Title\". This \"Title\" will be extracted from the name and will be the Title given to each name which can be \"Mr.\", \"Mrs.\", \"Dr.\" and many more. Refer to the last question of Week 1 Assignment for reference\n",
        "\n",
        "- Only create the extra column called \"Title\" in your existing dataframe, no need to report any answer as you will be using all these features in the next few questions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8WMMM6uIh7y"
      },
      "source": [
        "# Try to use regular expressions and use the pandas .apply() lambda function to solve \n",
        "# this as these are very powerful functions that will benefit you if learned now\n",
        "\n",
        "##### CODE #####\n",
        "df['Title'] = df['Name'].apply(lambda x: re.findall(\"[A-Za-z]+\\.\",x)[0])\n",
        "##### CODE #####"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9Eufd9xKpI9"
      },
      "source": [
        "## Q3. Use the dataframe from above, which should include the \"Title\" column now, if you have successfully completed Q2. Encode this \"Title\" column using any encoding technique of your choice. Explore the various encoding techniques by reading this article:\n",
        "\n",
        "https://www.kdnuggets.com/2021/05/deal-with-categorical-data-machine-learning.html\n",
        "\n",
        "\n",
        "- As a start you can use any of the following techniques but there are many more\n",
        "  - pandas get_dummies()\n",
        "  - One hot encoding\n",
        "  - Label encoding\n",
        "- Explore each of the above techniques as you will learn a lot just by reading them\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZahL6fWw2rqE",
        "outputId": "5d8abfff-01cb-4a4b-ed5f-d7f2519d6ebe"
      },
      "source": [
        "##### PANDAS GET_DUMMIES() #####\n",
        "pd.get_dummies(df,columns=[\"Title\"])\n",
        "##### PANDAS GET_DUMMIES() #####\n",
        "\n",
        "##### ONE HOT ENCODING #####\n",
        "ce_OHE = ce.OneHotEncoder(cols=['Title'])\n",
        "df = ce_OHE.fit_transform(df)\n",
        "##### ONE HOT ENCODING #####\n",
        "\n",
        "##### LABEL ENCODING #####\n",
        "le = LabelEncoder()\n",
        "df['Title_Cat'] = le.fit_transform(df[['Title']])\n",
        "##### LABEL ENCODING #####"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ2f7IRsLsGe"
      },
      "source": [
        "## Q4. This is an open ended Optional question. Explore the data as we have done for Week 3 class and create a new feature of your own. Add it as a new column to the dataframe. \n",
        "\n",
        "- This feature might help you get a good score for your Kaggle submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWATjfkyLPEt"
      },
      "source": [
        "# Follow the same process as the previous class notebooks on creating new columns. \n",
        "# This feature can be as simple as combining two columns by multiplying/dividing them with each other\n",
        "# Feel free to have a discussion in the group as this is a tricky Feature Engineering problem and might not be straightforward, hence optional.\n",
        "\n",
        "##### CODE #####\n",
        "df['Total_Family_Members'] = df['SibSp'] + df['Parch'] + 1\n",
        "df['AgeTimesPclass'] = df['Age'] * df['Pclass']\n",
        "##### CODE #####"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAT438zOMD3-"
      },
      "source": [
        "## Q5. Create a LogisticRegression model as done in class. Use the dataset you have developed after answering all the previous questions(make sure all the data is only numerical). Train your model on the \"train.csv\" file, and then make predictions on your \"test.csv\" file. Format your output EXACTLY as shown in class at the very end and EXACTLY like the \"gender_submission.csv\" file provided as part of the challenge\n",
        "\n",
        "- Once you have created your own submission file, submit it on Kaggle for evaluation\n",
        "- Report the score as obtained from the kaggle website here and store it in a variable called ```result```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQEzAarlMyzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111ec861-6998-4d41-c105-667195bd6615"
      },
      "source": [
        "##### CODE #####\n",
        "df[['female','male']] = pd.get_dummies(df['Sex'])\n",
        "df[[\"C\",\"Q\",\"S\"]] = pd.get_dummies(df['Embarked'])\n",
        "drop_features = ['PassengerId','Name','Sex','Ticket','Cabin','Embarked','Title']\n",
        "df.drop(drop_features,inplace=True,axis=1)\n",
        "df.fillna(method=\"ffill\",inplace=True)\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.loc[:,'Pclass':],df.Survived,\\\n",
        "                                                    test_size=0.1)\n",
        "model = LogisticRegression()\n",
        "model.fit(x_train,y_train)\n",
        "y_predictions = model.predict(x_test)\n",
        "\n",
        "df_test = pd.read_csv(\"./test.csv\")\n",
        "df_test[['female','male']] = pd.get_dummies(df_test['Sex'])\n",
        "df_test[[\"C\",\"Q\",\"S\"]] = pd.get_dummies(df_test['Embarked'])\n",
        "df_test['Title'] = df_test['Name'].apply(lambda x: re.findall('[A-Za-z]+\\.',x)[0])\n",
        "le = LabelEncoder()\n",
        "df_test['Title_Cat'] = le.fit_transform(df_test[['Title']])\n",
        "df_test['Total_Family_Members'] = df_test['SibSp'] + df_test['Parch'] + 1\n",
        "df_test['AgeTimesPclass'] = df_test['Age'] * df_test['Pclass']\n",
        "df_test.fillna(method=\"ffill\",inplace=True)\n",
        "drop_features = ['Sex','Title','Ticket','Name','Cabin',\"Embarked\"]\n",
        "df_test.drop(drop_features,inplace=True,axis=1)\n",
        "\n",
        "predictions_for_submission = model.predict(df_test.loc[:,\"Pclass\":])\n",
        "df_submission = df_test[['PassengerId']].copy()\n",
        "df_submission['Survived'] = predictions_for_submission\n",
        "df_submission.to_csv(\"submission_v1.csv\")\n",
        "##### CODE #####\n",
        "\n",
        "##### RESULT #####\n",
        "best = 0.77033      # without my added features\n",
        "result = 0.38516    # with my added features\n",
        "##### RESULT ##### "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}